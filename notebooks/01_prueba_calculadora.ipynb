{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0c738",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Celda 1\n",
    "# Importamos la función desde nuestro archivo .py\n",
    "from src.tools.calculadora import calcular_promedio_de_notas\n",
    "\n",
    "# Celda 2\n",
    "# Prueba funcional\n",
    "pregunta1 = \"¿cuál es el promedio entre 4.0, 5.5 y 7.0?\"\n",
    "print(calcular_promedio_de_notas(pregunta1))\n",
    "\n",
    "# Celda 3\n",
    "# Prueba con errores de tipeo\n",
    "pregunta2 = \"necesito la media de 3,5 y un 2\"\n",
    "print(calcular_promedio_de_notas(pregunta2))\n",
    "\n",
    "# Celda 4\n",
    "# Prueba sin números\n",
    "pregunta3 = \"hola cómo estás\"\n",
    "print(calcular_promedio_de_notas(pregunta3))```\n",
    "\n",
    "*Haz lo mismo en otro notebook para las funciones de `buscador.py`.*\n",
    "\n",
    "---\n",
    "\n",
    "### **Paso 4: Crear el Agente (El Cerebro Orquestador)**\n",
    "\n",
    "Ahora unimos todo en `agent.py`.\n",
    "\n",
    "```python\n",
    "# En src/agent.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import tool, AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Importamos nuestras herramientas personalizadas\n",
    "from src.tools.calculadora import calcular_promedio_de_notas\n",
    "from src.tools.buscador import buscar_en_faq, buscador_de_reglamentos\n",
    "\n",
    "# Cargar variables de entorno (el token de Hugging Face)\n",
    "load_dotenv()\n",
    "\n",
    "# --- 1. Módulo de Reglas de Seguridad ---\n",
    "def filtro_de_seguridad(consulta: str) -> bool:\n",
    "    \"\"\"\n",
    "    Filtro simple para detectar consultas inapropiadas.\n",
    "    Devuelve True si la consulta es segura, False si no lo es.\n",
    "    \"\"\"\n",
    "    consultas_prohibidas = [\"examen\", \"respuestas\", \"dame la prueba\", \"hackear\"]\n",
    "    for palabra in consultas_prohibidas:\n",
    "        if palabra in consulta.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# --- 2. Definición de Herramientas para LangChain ---\n",
    "# LangChain necesita que las funciones estén decoradas con @tool\n",
    "# La descripción (el docstring) es CRUCIAL. El LLM la usa para decidir qué herramienta usar.\n",
    "\n",
    "@tool\n",
    "def calculadora_academica(consulta: str) -> str:\n",
    "    \"\"\"\n",
    "    Útil para calcular el promedio de notas. La entrada debe ser la pregunta completa\n",
    "    del usuario que contiene las notas.\n",
    "    \"\"\"\n",
    "    return calcular_promedio_de_notas(consulta)\n",
    "\n",
    "@tool\n",
    "def buscador_faq(consulta: str) -> str:\n",
    "    \"\"\"\n",
    "    Útil para responder preguntas frecuentes sobre horarios, correos de contacto,\n",
    "    o procedimientos administrativos simples.\n",
    "    \"\"\"\n",
    "    return buscar_en_faq(consulta)\n",
    "\n",
    "@tool\n",
    "def buscador_reglamentos(consulta: str) -> str:\n",
    "    \"\"\"\n",
    "    Útil para responder preguntas específicas sobre el reglamento académico,\n",
    "    como reglas de asistencia, calificaciones, o condiciones de examen.\n",
    "    \"\"\"\n",
    "    return buscador_de_reglamentos.buscar(consulta)\n",
    "\n",
    "# --- 3. Creación del Agente ---\n",
    "def crear_agente():\n",
    "    \"\"\"\n",
    "    Configura y crea el agente conversacional.\n",
    "    \"\"\"\n",
    "    # Lista de herramientas que el agente podrá usar\n",
    "    tools = [calculadora_academica, buscador_faq, buscador_reglamentos]\n",
    "    \n",
    "    # Configuración del LLM (Modelo de Lenguaje) usando Hugging Face\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    # El prompt es la instrucción principal que le damos al agente\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Eres un asistente académico para estudiantes. Eres amable, directo y servicial. Usa tus herramientas para responder las preguntas.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "    \n",
    "    # Creamos el agente uniendo el LLM, las herramientas y el prompt\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    \n",
    "    # El Executor es el que realmente corre el agente y maneja los ciclos de pensamiento\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # verbose=True para ver los pensamientos del agente\n",
    "    \n",
    "    return agent_executor"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
